{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "# from tensorflow.python.client import device_lib\n",
    "# print(device_lib.list_local_devices())\n",
    "\n",
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "# tf.debugging.set_log_device_placement(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "from keras.initializers import RandomNormal\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model, Input\n",
    "from keras.layers import Conv2D, Conv2DTranspose, LeakyReLU, Activation\n",
    "from keras.layers import Concatenate, Dropout, BatchNormalization, LeakyReLU\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init = RandomNormal(stddev=0.02)\n",
    "# x = Input(shape=input_shape)\n",
    "# # encoder model\n",
    "# e1 = define_encoder_block(x, 64, batchnorm=False)\n",
    "# print(f'e1 {e1.shape}')\n",
    "# e2 = define_encoder_block(e1, 128)\n",
    "# print(f'e2 {e2.shape}')\n",
    "# e3 = define_encoder_block(e2, 256)\n",
    "# print(f'e3 {e3.shape}')\n",
    "# e4 = define_encoder_block(e3, 512)\n",
    "# print(f'e4 {e4.shape}')\n",
    "# e5 = define_encoder_block(e4, 512)\n",
    "# print(f'e5 {e5.shape}')\n",
    "# e6 = define_encoder_block(e5, 512)\n",
    "# print(f'e6 {e6.shape}')\n",
    "# e7 = define_encoder_block(e6, 512)\n",
    "# print(f'e7 {e7.shape}')\n",
    "# # bottleneck, no batch norm and relu\n",
    "# b = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(e7)\n",
    "# b = Activation('relu')(b)\n",
    "# print(f'b {b.shape}')\n",
    "# # decoder model\n",
    "# d1 = decoder_block(b, e7, 512)\n",
    "# print(f'd1 {d1.shape}')\n",
    "# d2 = decoder_block(d1, e6, 512, to_add=True)\n",
    "# print(f'd2 {d2.shape}')\n",
    "# d3 = decoder_block(d2, e5, 512)\n",
    "# print(f'd1 {d1.shape}')\n",
    "# d3 = decoder_block(d2, e5, 512)\n",
    "# print(f'd1 {d1.shape}')\n",
    "# d4 = decoder_block(d3, e4, 512, dropout=False)\n",
    "# print(f'd1 {d1.shape}')\n",
    "# d5 = decoder_block(d4, e3, 256, dropout=False)\n",
    "# print(f'd1 {d1.shape}')\n",
    "# d6 = decoder_block(d5, e2, 128, dropout=False)\n",
    "# print(f'd1 {d1.shape}')\n",
    "# d7 = decoder_block(d6, e1, 64, dropout=False)\n",
    "# print(f'd1 {d1.shape}')\n",
    "\n",
    "# # input_shape = (256, 192, 3)\n",
    "# # init = RandomNormal(stddev=0.02)\n",
    "# # x = Input(shape=input_shape)\n",
    "# # d = Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(x)\n",
    "# # d = Conv2D(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
    "# # d = Conv2D(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
    "# # d = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
    "# # # d = Conv2D(512, (4,4), padding='same', kernel_initializer=init)(d)\n",
    "# # d = Conv2DTranspose(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
    "    \n",
    "# #d = Conv2D(1, (4,4), padding='same', kernel_initializer=init)(d)\n",
    "# # d= Activation('sigmoid')(d)\n",
    "# d.shape, x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the discriminator model\n",
    "def define_discriminator(image_shape):\n",
    "    # weight initialization\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    # source image input\n",
    "    in_src_image = Input(shape=image_shape)\n",
    "    # target image input\n",
    "    in_target_image = Input(shape=image_shape)\n",
    "    # concatenate images channel-wise\n",
    "    merged = Concatenate()([in_src_image, in_target_image])\n",
    "    # C64     264*264 -> 132*132\n",
    "    d = Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(merged)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    # C128     132*132 -> 66*66\n",
    "    d = Conv2D(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
    "    d = BatchNormalization()(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    # C256     66*66 -> 33*33\n",
    "    d = Conv2D(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
    "    d = BatchNormalization()(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    # C512     33*33 -> 17*17 *512\n",
    "    d = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
    "    d = BatchNormalization()(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    # second last output layer 17*17*512 -> 17*17*512\n",
    "    d = Conv2D(512, (4,4), padding='same', kernel_initializer=init)(d)\n",
    "    d = BatchNormalization()(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    # patch output             17*17*512 -> 17*17 *1\n",
    "    d = Conv2D(1, (4,4), padding='same', kernel_initializer=init)(d)\n",
    "    patch_out = Activation('sigmoid')(d)\n",
    "    # define model\n",
    "    model = Model([in_src_image, in_target_image], patch_out)\n",
    "    # compile model\n",
    "    opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, loss_weights=[0.5])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define an encoder block\n",
    "def define_encoder_block(layer_in, n_filters, batchnorm=True):\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    # add downsampling layer\n",
    "    g = Conv2D(n_filters, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(layer_in)\n",
    "    # conditionally add batch normalization\n",
    "    if batchnorm:\n",
    "        g = BatchNormalization()(g, training=True)\n",
    "    # leaky relu activation\n",
    "    g = LeakyReLU(alpha=0.2)(g)\n",
    "    return g\n",
    " \n",
    "# define a decoder block\n",
    "def decoder_block(layer_in, skip_in, n_filters, dropout=True, to_add=False):\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    # add upsampling layer\\\n",
    "    \n",
    "    g = Conv2DTranspose(n_filters, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(layer_in)\n",
    "    # add batch normalization\n",
    "    g = BatchNormalization()(g, training=True)\n",
    "    # conditionally add dropout\n",
    "    if dropout:\n",
    "        g = Dropout(0.5)(g, training=True)\n",
    "    # merge with skip connection\n",
    "    g = Concatenate()([g, skip_in])\n",
    "    # relu activation\n",
    "    g = Activation('relu')(g)\n",
    "    return g\n",
    " \n",
    "# define the standalone generator model\n",
    "def define_generator(image_shape=(256,192)):\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    # image input\n",
    "    in_image = Input(shape=image_shape)\n",
    "    # encoder model\n",
    "    e1 = define_encoder_block(in_image, 64, batchnorm=False)\n",
    "    e2 = define_encoder_block(e1, 128)\n",
    "    e3 = define_encoder_block(e2, 256)\n",
    "    e4 = define_encoder_block(e3, 512)\n",
    "    e5 = define_encoder_block(e4, 512)\n",
    "    e6 = define_encoder_block(e5, 512)\n",
    "    e7 = define_encoder_block(e6, 512)\n",
    "    # bottleneck, no batch norm and relu\n",
    "    b = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(e7)\n",
    "    b = Activation('relu')(b)\n",
    "    # decoder model\n",
    "    d1 = decoder_block(b, e7, 512)\n",
    "    d2 = decoder_block(d1, e6, 512)\n",
    "    d3 = decoder_block(d2, e5, 512)\n",
    "    d4 = decoder_block(d3, e4, 512, dropout=False)\n",
    "    d5 = decoder_block(d4, e3, 256, dropout=False)\n",
    "    d6 = decoder_block(d5, e2, 128, dropout=False)\n",
    "    d7 = decoder_block(d6, e1, 64, dropout=False)\n",
    "    # output\n",
    "    g = Conv2DTranspose(3, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d7)\n",
    "    out_image = Activation('tanh')(g)\n",
    "    # define model\n",
    "    model = Model(in_image, out_image)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_gan(g_model, d_model, image_shape):\n",
    "    # make weights in the discriminator not trainable\n",
    "    d_model.trainable = False\n",
    "    \n",
    "    in_src = Input(shape=image_shape)\n",
    "    # connect the source image to the generator input\n",
    "    gen_out = g_model(in_src)\n",
    "    # connect the source input and generator output to the discriminator input\n",
    "    dis_out = d_model([in_src, gen_out])\n",
    "    # src image as input, generated image and classification output\n",
    "    model = Model(in_src, [dis_out, gen_out])\n",
    "    # compile model\n",
    "    opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "    model.compile(loss=['binary_crossentropy', 'mae'], optimizer=opt, loss_weights=[1,100])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_model(gan_model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and prepare training images\n",
    "def load_real_samples(filename):\n",
    "    # load compressed arrays\n",
    "    data = np.load(filename)\n",
    "    # unpack arrays\n",
    "    X1, X2 = data['arr_0'], data['arr_1']\n",
    "    # scale from [0,255] to [-1,1]\n",
    "    X1 = (X1 - 127.5) / 127.5\n",
    "    X2 = (X2 - 127.5) / 127.5\n",
    "    return [X1, X2]\n",
    "\n",
    "\n",
    "# select a batch of random samples, returns images and target\n",
    "def generate_real_samples(dataset, n_samples, patch_shape):\n",
    "    # unpack dataset\n",
    "    trainA, trainB = dataset\n",
    "    # choose random instances\n",
    "    ix = np.random.randint(0, trainA.shape[0], n_samples)\n",
    "    # retrieve selected images\n",
    "    X1, X2 = trainA[ix], trainB[ix]\n",
    "    # generate 'real' class labels (1)\n",
    "    y = np.ones((n_samples, patch_shape, patch_shape, 1))\n",
    "    return [X1, X2], y, ix\n",
    "\n",
    "\n",
    "# generate a batch of images, returns images and targets\n",
    "def generate_fake_samples(g_model, samples, patch_shape):\n",
    "    # generate fake instance\n",
    "    X = g_model.predict(samples)\n",
    "    # create 'fake' class labels (0)\n",
    "    y = np.zeros((len(X), patch_shape, patch_shape, 1))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neptune and pther logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate samples and save as a plot and save the model\n",
    "def summarize_performance(step, g_model, d_model, dataset, \n",
    "                          val=False, n_samples=3):\n",
    "    # select a sample of input images\n",
    "    [X_realA, X_realB], _, idx = generate_real_samples(dataset, n_samples, 1)\n",
    "    # generate a batch of fake samples\n",
    "    X_fakeB, _ = generate_fake_samples(g_model, X_realA, 1)\n",
    "    # scale all pixels from [-1,1] to [0,1]\n",
    "    X_realA = (X_realA + 1) / 2.0\n",
    "    X_realB = (X_realB + 1) / 2.0\n",
    "    X_fakeB = (X_fakeB + 1) / 2.0\n",
    "    \n",
    "    fig, axes = plt.subplots(3, 3)\n",
    "\n",
    "    # plot real source images\n",
    "    for i in range(n_samples):\n",
    "        #pyplot.subplot(3, n_samples, 1 + i)\n",
    "        axes[0][i].axis('off')\n",
    "        axes[0][i].imshow(X_realA[i])\n",
    "    # plot generated target image\n",
    "    for i in range(n_samples):\n",
    "        #pyplot.subplot(3, n_samples, 1 + n_samples + i)\n",
    "        axes[1][i].axis('off')\n",
    "        axes[1][i].imshow(X_fakeB[i])\n",
    "    # plot real target image\n",
    "    for i in range(n_samples):\n",
    "        #pyplot.subplot(3, n_samples, 1 + n_samples*2 + i)\n",
    "        axes[2][i].axis('off')\n",
    "        axes[2][i].imshow(X_realB[i])\n",
    "    # save plot to file\n",
    "    #filename1 = 'plot_%06d_%d_%d_%d.png' % (step+1, idx[0], idx[1], idx[2])\n",
    "    name = 'val' if val is True else 'train'        \n",
    "    neptune.log_image(name + '_img', fig)\n",
    "    del fig, axes\n",
    "    #pyplot.savefig(filename1)\n",
    "    #pyplot.close()\n",
    "    \n",
    "    # save the generator model\n",
    "    if val is False:\n",
    "        filename2 = 'models/generator_%06d' % (step+1)\n",
    "        g_model.save(filename2)\n",
    "        #neptune.log_artifact(filename2)\n",
    "        print('Saved model')\n",
    "        \n",
    "    print('>Saved ' + name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Project(declot/pix2pix)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import neptune\n",
    "from neptunecontrib.monitoring.keras import NeptuneMonitor\n",
    "\n",
    "neptune.init('declot/pix2pix')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "tf.debugging.set_log_device_placement(False)\n",
    "\n",
    "cm_params = {'cmap': 'Blues', 'annot': True, 'fmt':'d', \n",
    "             'xticklabels': ['0_pred', '1_pred'],\n",
    "             'yticklabels': ['0_true', '1_true']}\n",
    "\n",
    "\n",
    "def get_dicriminator_metric(i, X_val_realA, X_val_realB, X_val_fakeB, \n",
    "                            y_val_real, y_val_fake,\n",
    "                            val=False):\n",
    "    name = 'val' if val else 'train'\n",
    "    pred_real = d_model.predict_on_batch([X_val_realA, X_val_realB])\n",
    "    pred_fake = d_model.predict_on_batch([X_val_realA, X_val_fakeB])\n",
    "\n",
    "    pred_real = np.where(pred_real.ravel() > 0.5 ,1,0)\n",
    "    pred_fake = np.where(pred_fake.ravel() > 0.5 ,1,0)\n",
    "    y_val_real = y_val_real.ravel()\n",
    "    y_val_fake = y_val_fake.ravel()\n",
    "\n",
    "    y_true = np.concatenate([y_val_real, y_val_fake], axis=0)\n",
    "    y_pred = np.concatenate([pred_real, pred_fake], axis=0)\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    neptune.log_metric(name+'_accuracy_total', i, acc)\n",
    "    neptune.log_metric(name+'_accuracy_real', i, accuracy_score(y_val_real, pred_real))\n",
    "    neptune.log_metric(name+'_accuracy_fake', i, accuracy_score(y_val_fake, pred_fake))\n",
    "\n",
    "    return y_true, y_pred\n",
    "\n",
    "def train(d_model, g_model, gan_model, dataset, dataset_val=None,\n",
    "          n_epochs=100, n_batch=1, iters_to_save=None):\n",
    "    # determine the output square shape of the discriminator\n",
    "    n_patch = d_model.output_shape[1]\n",
    "    print('n_patch', n_patch)\n",
    "    # unpack dataset\n",
    "    trainA, trainB = dataset\n",
    "    # calculate the number of batches per training epoch\n",
    "    bat_per_epo = int(len(trainA) / n_batch)\n",
    "    # calculate the number of training iterations\n",
    "    n_steps = bat_per_epo * n_epochs\n",
    "    \n",
    "    print(f'Total steps: {n_steps:d}\\n1 epochs after {bat_per_epo:d} steps')\n",
    "    # determine for which iteration  number the log will be saved\n",
    "    if iters_to_save is None:\n",
    "        iters_to_save = list(range(0, n_steps+1, bat_per_epo*10))\n",
    "        iters_to_save.pop(0)\n",
    "        iters_to_save.insert(0, 1)\n",
    "    # manually enumerate epochs\n",
    "    for i in range(n_steps):\n",
    "        # select a batch of real samples\n",
    "        [X_realA, X_realB], y_real,_ = generate_real_samples(dataset, n_batch, n_patch)\n",
    "        # generate a batch of fake samples\n",
    "        X_fakeB, y_fake = generate_fake_samples(g_model, X_realA, n_patch)\n",
    "        # update discriminator for real samples\n",
    "        d_loss1 = d_model.train_on_batch([X_realA, X_realB], y_real)\n",
    "        # update discriminator for generated samples\n",
    "        d_loss2 = d_model.train_on_batch([X_realA, X_fakeB], y_fake)\n",
    "        # update the generator\n",
    "        g_loss, _, _ = gan_model.train_on_batch(X_realA, [y_real, X_realB])\n",
    "        # summarize performance\n",
    "        neptune.log_metric('d_loss_real', d_loss1)\n",
    "        neptune.log_metric('d_loss_fake', d_loss2)\n",
    "        neptune.log_metric('g_loss', g_loss)\n",
    "        # summarize model performance\n",
    "        if i% bat_per_epo == 0 and dataset_val is not None: \n",
    "            [X_val_realA, X_val_realB], y_val_real,_ = generate_real_samples(dataset_val, n_batch, n_patch)\n",
    "            X_val_fakeB, y_val_fake = generate_fake_samples(g_model, X_val_realA, n_patch)\n",
    "            \n",
    "            d_val_loss1 = d_model.test_on_batch([X_val_realA, X_val_realB], y_val_real)\n",
    "            d_val_loss2 = d_model.test_on_batch([X_val_realA, X_val_fakeB], y_val_fake)\n",
    "            neptune.log_metric('d_val_loss_real', i, d_loss1)\n",
    "            neptune.log_metric('d_val_loss_fake',i,  d_loss2)\n",
    "            \n",
    "            _,_ = get_dicriminator_metric(i, X_val_realA, X_val_realB, X_val_fakeB, \n",
    "                                    y_val_real, y_val_fake,\n",
    "                                    val=True)\n",
    "            y_true, y_pred = get_dicriminator_metric(i, X_realA, X_realB, X_fakeB, \n",
    "                                    y_real, y_fake,\n",
    "                                    val=False)\n",
    "            \n",
    "            \n",
    "        if i+1 in iters_to_save: #(bat_per_epo * 10) \n",
    "            print('>%d, d1[%.3f] d2[%.3f] g[%.3f]' % (i+1, d_loss1, d_loss2, g_loss))\n",
    "            summarize_performance(i, g_model, d_model, dataset)\n",
    "            summarize_performance(i, g_model, d_model, dataset_val, val=True)\n",
    "            \n",
    "            cm = confusion_matrix(y_true, y_pred)\n",
    "            fig, ax = plt.subplots()\n",
    "            sns.heatmap(cm, **cm_params, ax=ax)\n",
    "            neptune.log_image('cm', fig)\n",
    "            del fig, ax\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './dataset/dataset_batch1.npz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-7f619d02482d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# LOAD DATA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdataset_ini\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_real_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./dataset/dataset_batch1.npz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loaded'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_ini\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_ini\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mdataset_ini\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdataset_ini\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-f8516a8b6e78>\u001b[0m in \u001b[0;36mload_real_samples\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_real_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# load compressed arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;31m# unpack arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mX1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'arr_0'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'arr_1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './dataset/dataset_batch1.npz'"
     ]
    }
   ],
   "source": [
    "# LOAD DATA\n",
    "dataset_ini = load_real_samples('./dataset/dataset_batch1.npz')\n",
    "\n",
    "print('Loaded', dataset_ini[0].shape, dataset_ini[1].shape)\n",
    "assert dataset_ini[0].shape == dataset_ini[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NoExperimentContext",
     "evalue": "Unable to find current active experiment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNoExperimentContext\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-c760baf83430>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mneptune\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/neptune/__init__.py\u001b[0m in \u001b[0;36mstop\u001b[0;34m(traceback)\u001b[0m\n\u001b[1;32m    375\u001b[0m     \u001b[0mAlias\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mmeth\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mneptune\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperiments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m     \"\"\"\n\u001b[0;32m--> 377\u001b[0;31m     \u001b[0mget_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/neptune/__init__.py\u001b[0m in \u001b[0;36mget_experiment\u001b[0;34m()\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mproject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_current_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/neptune/projects.py\u001b[0m in \u001b[0;36m_get_current_experiment\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    610\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experiments_stack\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 612\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mNoExperimentContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_push_new_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_experiment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNoExperimentContext\u001b[0m: Unable to find current active experiment"
     ]
    }
   ],
   "source": [
    "neptune.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://ui.neptune.ai/declot/pix2pix/e/PIX-23\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train_size': 2000, 'batch_size': 32, 'n_epochs': 100}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SET PARAMS\n",
    "\n",
    "train_size = 2000\n",
    "batch_size = 32\n",
    "n_epochs = 100\n",
    "\n",
    "name_exp = 'first commit'\n",
    "params = {'train_size': train_size,\n",
    "         'batch_size': batch_size,\n",
    "         'n_epochs': n_epochs}\n",
    "\n",
    "neptune.create_experiment(name=name_exp, params=params,\n",
    "                         upload_source_files=['Pix2pix model.ipynb'])\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = [dataset_ini[0][:train_size], dataset_ini[1][:train_size]]\n",
    "# define input shape based on the loaded dataset\n",
    "image_shape = dataset[0].shape[1:]\n",
    "\n",
    "dataset_val = [dataset_ini[0][train_size:], dataset_ini[1][train_size:]]\n",
    "\n",
    "if dataset_val[0].shape[0] == 0:\n",
    "    dataset_val = load_real_samples('./dataset/dataset_batch2.npz')\n",
    "    dataset_val = dataset_val[0][:1000], dataset_val[1][:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_val[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# define the models\n",
    "d_model = define_discriminator(image_shape)\n",
    "g_model = define_generator(image_shape)\n",
    "# define the composite model\n",
    "gan_model = define_gan(g_model, d_model, image_shape)\n",
    "# train model\n",
    "train(d_model, g_model, gan_model, dataset, dataset_val,\n",
    "      n_epochs=n_epochs, n_batch=batch_size)\n",
    "\n",
    "neptune.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded (2000, 256, 256, 3) (2000, 256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "dataset_test = load_real_samples('./dataset/dataset_batch2.npz')\n",
    "print('Loaded', dataset_test[0].shape, dataset_test[1].shape)\n",
    "assert dataset_test[0].shape == dataset_test[1].shape\n",
    "\n",
    "# define input shape based on the loaded dataset\n",
    "image_shape = dataset_test[0].shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "file_model = 'models/generator_000001.h5'\n",
    "# g_model.save(file_model)\n",
    "model = keras.models.load_model(file_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 256, 256, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 128, 128, 64) 3136        input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 128, 128, 64) 0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 64, 64, 128)  131200      leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 64, 64, 128)  512         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, 64, 64, 128)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 256)  524544      leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 32, 32, 256)  1024        conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)       (None, 32, 32, 256)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 16, 16, 512)  2097664     leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 16, 16, 512)  2048        conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)       (None, 16, 16, 512)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 8, 8, 512)    4194816     leaky_re_lu_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 8, 8, 512)    2048        conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)       (None, 8, 8, 512)    0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 4, 4, 512)    4194816     leaky_re_lu_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 4, 4, 512)    2048        conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)      (None, 4, 4, 512)    0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 2, 2, 512)    4194816     leaky_re_lu_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 2, 2, 512)    2048        conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)      (None, 2, 2, 512)    0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 1, 1, 512)    4194816     leaky_re_lu_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 1, 1, 512)    0           conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose (Conv2DTranspo (None, 2, 2, 512)    4194816     activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 2, 2, 512)    2048        conv2d_transpose[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 2, 2, 512)    0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 2, 2, 1024)   0           dropout[0][0]                    \n",
      "                                                                 leaky_re_lu_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 2, 2, 1024)   0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 4, 4, 512)    8389120     activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 4, 4, 512)    2048        conv2d_transpose_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 4, 4, 512)    0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 4, 4, 1024)   0           dropout_1[0][0]                  \n",
      "                                                                 leaky_re_lu_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 4, 4, 1024)   0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 8, 8, 512)    8389120     activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 8, 8, 512)    2048        conv2d_transpose_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 8, 8, 512)    0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 8, 8, 1024)   0           dropout_2[0][0]                  \n",
      "                                                                 leaky_re_lu_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 8, 8, 1024)   0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 16, 16, 512)  8389120     activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 16, 16, 512)  2048        conv2d_transpose_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 16, 16, 1024) 0           batch_normalization_13[0][0]     \n",
      "                                                                 leaky_re_lu_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 16, 16, 1024) 0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTrans (None, 32, 32, 256)  4194560     activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 32, 32, 256)  1024        conv2d_transpose_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 32, 32, 512)  0           batch_normalization_14[0][0]     \n",
      "                                                                 leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 32, 32, 512)  0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTrans (None, 64, 64, 128)  1048704     activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 64, 64, 128)  512         conv2d_transpose_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 64, 64, 256)  0           batch_normalization_15[0][0]     \n",
      "                                                                 leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 64, 64, 256)  0           concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_6 (Conv2DTrans (None, 128, 128, 64) 262208      activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 128, 128, 64) 256         conv2d_transpose_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 128, 128, 128 0           batch_normalization_16[0][0]     \n",
      "                                                                 leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 128, 128, 128 0           concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_7 (Conv2DTrans (None, 256, 256, 3)  6147        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 256, 256, 3)  0           conv2d_transpose_7[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 54,429,315\n",
      "Trainable params: 54,419,459\n",
      "Non-trainable params: 9,856\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.vis_utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_performance_test(g_model, dataset, n_samples=3):\n",
    "    # select a sample of input images\n",
    "    [X_realA, X_realB], _, idx = generate_real_samples(dataset, n_samples, 1)\n",
    "    # generate a batch of fake samples\n",
    "    X_fakeB, _ = generate_fake_samples(g_model, X_realA, 1)\n",
    "    # scale all pixels from [-1,1] to [0,1]\n",
    "    X_realA = (X_realA + 1) / 2.0\n",
    "    X_realB = (X_realB + 1) / 2.0\n",
    "    X_fakeB = (X_fakeB + 1) / 2.0\n",
    "    # plot real source images\n",
    "    for i in range(n_samples):\n",
    "        pyplot.subplot(3, n_samples, 1 + i)\n",
    "        pyplot.axis('off')\n",
    "        pyplot.imshow(X_realA[i])\n",
    "    # plot generated target image\n",
    "    for i in range(n_samples):\n",
    "        pyplot.subplot(3, n_samples, 1 + n_samples + i)\n",
    "        pyplot.axis('off')\n",
    "        pyplot.imshow(X_fakeB[i])\n",
    "    # plot real target image\n",
    "    for i in range(n_samples):\n",
    "        pyplot.subplot(3, n_samples, 1 + n_samples*2 + i)\n",
    "        pyplot.axis('off')\n",
    "        pyplot.imshow(X_realB[i])\n",
    "    # save plot to file\n",
    "    filename1 = 'test_plot_%d_%d_%d.png' % (idx[0], idx[1], idx[2])\n",
    "    pyplot.savefig(filename1)\n",
    "    pyplot.close()\n",
    "    # save the generator model\n",
    "#     filename2 = 'model_%06d.h5' % (step+1)\n",
    "#     g_model.save(filename2)\n",
    "#     print('>Saved: %s and %s' % (filename1, filename2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_performance_test(model, dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "notify_time": "5"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
